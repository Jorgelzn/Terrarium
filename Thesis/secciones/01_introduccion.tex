\chapter{Introduction}
%%---------------------------------------------------------

In this chapter it is presented the foundations of the work. 

\section{Motivation}

The field of artificial intelligence has been increasing it´s popularity in the last years. Since the publication of the paper "Attention is all you need" \cite{attention}, the transformer arquitecture that it introduced has brought the creation of gigantic models cappable of processsing huge amounts of data. This is the case for the large language models and the generative ones.

However all these improvements are based in the classic core idea of suppervised learning, with the only difference been the arquitectures that allow much more examples in the training process. If we continue with this trend, all the research advancements will be reserved for the big companies who have economic resources that grant them access to a high volume of infrastructure for creating huge models. With this scenario in mind, it is interesting that we take a step back and consider exploring other algorithms and learning methods that do not only deppend on raw data and computation power.

From the many types of algorithms (agents intro)

When working with agents, it is implied that they need an environment to interact with, receiving feedback, and performing actions that modify their surroundings. The research about intelligent agents its limited by the available environments that can be used to test them. Training an agent on real life scenarios is expensive and dangerous, while many of the digital simulators are centered in robotics or are commercial software, and there are few which focus on agent´s behaviour.

Reinforcement Learning tries to model behaviour for intelligent agents with no more data than the input that the proper agents receive from the environment. This family of algorithms are heavily based in game theory and the concept of reward. As stated in the publication "Reward is Enough"  \cite{rewardIsEnough}, the idea of receiving possitive feedback creates a strong guidance for learning complex tasks.

Natural Scenario and reward

\section{Objectives}

\section{Problem Description}

\section{State of the art}

\subsection{Simulators}

\subsection{Multi-Agents}

\subsection{Deep Reinforcement Learning}

%%---------------------------------------------------------